<!-- 
To deploy on GitHub Pages:
1. Create a new GitHub repository.
2. Add this file as hot-or-not-ai.html in the root of the repository.
3. Go to repository settings > Pages > Select main branch and root directory.
4. Access via https://<username>.github.io/<repo>/hot-or-not-ai.html (not the raw file URL).
-->

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Hot or Not AI</title>
  <style>
    body { 
      font-family: 'Arial', sans-serif; 
      text-align: center; 
      margin: 20px; 
      background: linear-gradient(to bottom, #ff1493, #ff69b4); 
      color: white; 
    }
    .container { max-width: 400px; margin: auto; }
    #preview { max-width: 300px; max-height: 300px; display: none; border: 5px solid white; border-radius: 15px; }
    #video { max-width: 300px; display: none; border: 5px solid white; border-radius: 15px; }
    #loader { display: none; font-size: 18px; color: gold; }
    #error { color: yellow; font-size: 16px; }
    #score { font-size: 36px; font-weight: bold; margin-top: 20px; color: gold; text-shadow: 2px 2px 4px #000; }
    button, input { 
      margin: 10px; 
      padding: 12px 24px; 
      font-size: 16px; 
      background: #ff69b4; 
      color: white; 
      border: none; 
      border-radius: 30px; 
      cursor: pointer; 
      box-shadow: 0 4px 8px rgba(0,0,0,0.2); 
    }
    button:hover { background: #ff1493; }
    h1 { font-family: 'Georgia', serif; font-style: italic; }
  </style>
</head>
<body>
  <div class="container">
    <h1>Hot or Not AI ðŸ’‹</h1>
    <input type="file" id="upload" accept="image/*">
    <button id="cameraBtn">Use Camera ðŸ“¸</button>
    <video id="video" autoplay playsinline></video>
    <button id="snap" style="display: none;">Snap Photo ðŸ“·</button>
    <img id="preview" alt="Preview">
    <div id="score"></div>
    <div id="loader">Loading...</div>
    <div id="error"></div>
  </div>
  <canvas id="canvas" style="display: none;"></canvas>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
  <script>
    const video = document.getElementById('video');
    const snapBtn = document.getElementById('snap');
    const cameraBtn = document.getElementById('cameraBtn');
    const upload = document.getElementById('upload');
    const preview = document.getElementById('preview');
    const scoreDiv = document.getElementById('score');
    const loader = document.getElementById('loader');
    const errorDiv = document.getElementById('error');
    const canvas = document.getElementById('canvas');

    function showLoader(show) {
      loader.style.display = show ? 'block' : 'none';
    }

    function showError(msg) {
      errorDiv.innerText = msg;
    }

    function clearError() {
      errorDiv.innerText = '';
    }

    async function init() {
      showLoader(true);
      try {
        await tf.setBackend('webgl');
        if (!tf.env().getBool('IS_BROWSER') || !tf.env().getBool('WEBGL_RENDER_FLOAT32_ENABLED')) {
          await tf.setBackend('cpu');
        }
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri('https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights'),
          faceapi.nets.faceLandmark68Net.loadFromUri('https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights')
        ]);
      } catch (e) {
        showError('Failed to load models: ' + e.message);
      }
      showLoader(false);
    }

    function getCenter(positions, indices) {
      let sumX = 0, sumY = 0;
      indices.forEach(i => {
        sumX += positions[i].x;
        sumY += positions[i].y;
      });
      return {x: sumX / indices.length, y: sumY / indices.length};
    }

    function dist(p1, p2) {
      return Math.sqrt(Math.pow(p1.x - p2.x, 2) + Math.pow(p1.y - p2.y, 2));
    }

    async function processImage(input) {
      showLoader(true);
      clearError();
      scoreDiv.innerText = '';
      preview.style.display = 'block';
      preview.src = input.src || input.toDataURL();
      try {
        const detection = await faceapi.detectSingleFace(input, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
        let score;
        if (detection) {
          const positions = detection.landmarks.positions;
          // Compute centers
          const leftEye = getCenter(positions, [36,37,38,39,40,41]);
          const rightEye = getCenter(positions, [42,43,44,45,46,47]);
          // Ratios
          const faceWidth = dist(positions[0], positions[16]);
          const interOcular = dist(leftEye, rightEye);
          const ratio1 = interOcular / faceWidth;
          const ideal1 = 0.46;
          const dev1 = Math.abs(ratio1 - ideal1) / ideal1;
          const mouthWidth = dist(positions[48], positions[54]);
          const noseWidth = dist(positions[31], positions[35]);
          const ratio2 = mouthWidth / noseWidth;
          const ideal2 = 1.618;
          const dev2 = Math.abs(ratio2 - ideal2) / ideal2;
          // Symmetry
          const leftEyeWidth = dist(positions[36], positions[39]);
          const rightEyeWidth = dist(positions[42], positions[45]);
          const avgEyeWidth = (leftEyeWidth + rightEyeWidth) / 2;
          const sym1 = Math.abs(leftEyeWidth - rightEyeWidth) / avgEyeWidth;
          // Average dev
          const avgDev = (dev1 + dev2 + sym1) / 3;
          const rawScore = 10 - 30 * avgDev;
          score = Math.max(1, Math.min(10, rawScore)).toFixed(1);
        } else {
          score = (Math.random() * 9 + 1).toFixed(1);
          showError('No face detected, providing an estimated score.');
        }
        scoreDiv.innerText = `Score: ${score} / 10`;
      } catch (e) {
        showError('Error processing image: ' + e.message);
      }
      showLoader(false);
    }

    cameraBtn.onclick = async () => {
      clearError();
      preview.style.display = 'none';
      scoreDiv.innerText = '';
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
        video.style.display = 'block';
        video.onloadedmetadata = () => {
          if (video.videoWidth > 0 && video.videoHeight > 0) {
            snapBtn.style.display = 'block';
          } else {
            showError('Camera metadata not loaded properly.');
          }
        };
      } catch (e) {
        showError('Camera access error: ' + e.message);
      }
    };

    snapBtn.onclick = () => {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      video.srcObject.getTracks().forEach(track => track.stop());
      video.style.display = 'none';
      snapBtn.style.display = 'none';
      processImage(canvas);
    };

    upload.onchange = (e) => {
      const file = e.target.files[0];
      if (file) {
        clearError();
        const reader = new FileReader();
        reader.onload = (event) => {
          const image = new Image();
          image.onload = () => {
            if (image.width > 0 && image.height > 0) {
              processImage(image);
            } else {
              showError('Invalid image.');
            }
          };
          image.src = event.target.result;
        };
        reader.readAsDataURL(file);
      }
    };

    init();
  </script>
</body>
</html>